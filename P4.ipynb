{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Advanced Lane Lines** \n",
    "***\n",
    "### The Goal of this Project\n",
    "In this project, your goal is to write a software pipeline to identify the lane boundaries in a video from a front-facing camera on a car. The camera calibration images, test road images, and project videos are available in the [project repository](https://github.com/udacity/CarND-Advanced-Lane-Lines).\n",
    "\n",
    "### The steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Apply a perspective transform to rectify distortion corrected image (\"birds-eye view\").\n",
    "4. Use color threshold and/or gradient transforms to create a binary image.\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the radius of curvature and car offset.\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "9. Line fit based on sanity checks.\n",
    "10. Integrate the pipeline and test on images.\n",
    "11. Test on videos.\n",
    "\n",
    "\n",
    "\n",
    "The images for camera calibration are stored in the folder called camera_cal. The images in test_images are for testing your pipeline on single frames. If you want to extract more test images from the videos, you can simply use an image writing method like cv2.imwrite(), i.e., you can read the video in frame by frame as usual, and for frames you want to save for later you can write to an image file.\n",
    "\n",
    "To help the reviewer examine your work, please save examples of the output from each stage of your pipeline in the folder called ouput_images, and include a description in your writeup for the project of what each image shows. The video called project_video.mp4 is the video your pipeline should work well on.\n",
    "\n",
    "The challenge_video.mp4 video is an extra (and optional) challenge for you if you want to test your pipeline under somewhat trickier conditions. The harder_challenge.mp4 video is another optional challenge and is brutal!\n",
    "\n",
    "If you're feeling ambitious (again, totally optional though), don't stop there! We encourage you to go out and take video of your own, calibrate your camera and show us how you would implement this project from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1: Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "\n",
    "(i) Use chessboard images and OpenCV functions [findChessboardCorners()](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.findChessboardCorners) and [drawChessboardCorners()](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.drawChessboardCorners) to [extract image points and object points](https://github.com/udacity/CarND-Camera-Calibration/blob/master/camera_calibration.ipynb)\n",
    "(ii) Use the OpenCV functions [cv2.calibrateCamera()](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html) to calculate camera calibration matrix and distortion coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Results\n",
    "def visualize_results(img1, img2, str1, str2):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(str1, fontsize=30)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(str2, fontsize=30)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the camera calibration matrix and distortion coefficients\n",
    "def compute_camera(camera_cal_images, init_img, nx, ny):\n",
    "    # extract object points and image points for camera calibration\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    #images = glob.glob('camera_cal/calib*.jpg')\n",
    "    images = glob.glob(camera_cal_images)\n",
    "    \n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.copy(img_rgb)\n",
    "        # Find the chessboard corners\n",
    "        #ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "        ret, corners = cv2.findChessboardCorners(img_rgb, (nx,ny), None)\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Draw and display the corners\n",
    "            img_o = cv2.drawChessboardCorners(img_rgb, (nx,ny), corners, ret)\n",
    "            #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "            #cv2.imwrite(write_name, img)\n",
    "            #cv2.imshow('img', img)\n",
    "            #cv2.waitKey(1000)\n",
    "            visualize_results(img, img_o, 'Origial Image', 'Image Corners')\n",
    "    #cv2.destroyAllWindows()\n",
    "    init_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    init_img_size = (init_img.shape[1], init_img.shape[0])\n",
    "    #print(\"image size=\", img_size)\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, init_img_size, None, None)\n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump(dist_pickle, open(\"output_images/wide_dist_pickle.p\", \"wb\" ) )\n",
    "    #print(\"Camera calib. is done (one time only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test compute_camera \n",
    "%matplotlib inline\n",
    "nx  = 9\n",
    "ny = 6\n",
    "camera_cal_images = 'camera_cal/calib*.jpg'\n",
    "init_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "compute_camera(camera_cal_images, init_img, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2: Apply a distortion correction to raw images.\n",
    "\n",
    "Use the OpenCV functions [cv2.calibrateCamera()](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html) and [cv2.undistort()](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_calib3d/py_calibration/py_calibration.html) to compute the calibration and undistortion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distortion Correction\n",
    "def dist_correct(img):\n",
    "    # Read in the saved camera matrix and distortion coefficients\n",
    "    # These are the arrays you calculated using cv2.calibrateCamera()\n",
    "    dist_pickle = pickle.load(open(\"output_images/wide_dist_pickle.p\" , \"rb\" ) )\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    # undistort\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    undist = cv2.cvtColor(undist, cv2.COLOR_BGR2RGB)\n",
    "    #print(\"1-Camera distortion correction is done...\")\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test dist_correct on checker board images\n",
    "t_images = sorted(glob.glob('camera_cal/*.jpg'))\n",
    "for idx, pname,  in enumerate(t_images):\n",
    "    fname = pname.split('/')[-1]\n",
    "    # Read in an image\n",
    "    img = cv2.imread(pname)\n",
    "    #test_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Run the function\n",
    "    undist = dist_correct(img)\n",
    "    # Save and visualize output images\n",
    "    cv2.imwrite('output_images/'+'output_'+fname, undist)\n",
    "    visualize_results(img, undist, pname, 'output_images/'+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test dist_correct on all test images\n",
    "t_images = sorted(glob.glob('test_images/*.jpg'))\n",
    "for idx, pname,  in enumerate(t_images):\n",
    "    fname = pname.split('/')[-1]\n",
    "    # Read in an image\n",
    "    img = cv2.imread(pname)\n",
    "    test_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Run the function\n",
    "    undist = dist_correct(img)\n",
    "    # Save and/or visualize output images\n",
    "    cv2.imwrite('output_images/'+'output_'+fname, undist)\n",
    "    visualize_results(test_image, undist, pname, 'output_images/'+fname )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3: Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read source image points using interactive window\n",
    "#%matplotlib qt5 \n",
    "%matplotlib inline \n",
    "image = cv2.imread('test_images/straight_lines1.jpg')\n",
    "test_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.subplots(1, 1, figsize=(10,5))\n",
    "plt.imshow(test_image)\n",
    "# source image points (read from interactive window)\n",
    "plt.plot(720, 470, \".\") # top right\n",
    "plt.plot(1031, 670, \".\") # bottom right\n",
    "plt.plot(275, 670, \".\") # bottom left\n",
    "plt.plot(569, 470, \".\") # top left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transform \n",
    "def corners_unwarp(img):\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # source points\n",
    "    src = np.float32([[720, 470],[1031, 670],[275, 670],[569, 470]])\n",
    "    # destination points\n",
    "    dst = np.float32([[1031,100],[1031,670],[275,670],[275,100]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src) \n",
    "    \n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    #print(\"Perspective transform is done...\")\n",
    "    return warped, M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test Perspective Transform\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    # Plot the result\n",
    "    visualize_results(img, birds_eye, pname, 'Bird\\'s Eye Image%s'%idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4: Use color threshold and/or gradient transforms to create a binary image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Color Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R of RGB \n",
    "def r_color_thresh(img, r_thresh=(0, 255)):\n",
    "    r_channel = img[:,:,0]\n",
    "    r_binary_output = np.zeros_like(r_channel)\n",
    "    r_binary_output[(r_channel > r_thresh[0]) & (r_channel <= r_thresh[1])] = 1\n",
    "    return r_binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test of RGB\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    r_binary_output = r_color_thresh(img, r_thresh=(215, 255))\n",
    "    # Plot the result\n",
    "    #visualize_results(img, r_binary_output, pname, 'R Color Thresh.%s'%idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V of HSV\n",
    "def v_color_thresh(img, v_thresh=(0, 255)):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    v_binary_output = np.zeros_like(v_channel)\n",
    "    v_binary_output[(v_channel > v_thresh[0]) & (v_channel <= v_thresh[1])] = 1\n",
    "    return v_binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test of HSV\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    v_binary_output = v_color_thresh(img, v_thresh=(220, 255))\n",
    "    # Plot the result\n",
    "    #visualize_results(img, v_binary_output, pname, 'V Color Thresh.%s'%idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L of LUV\n",
    "def l_color_thresh(img, l_thresh=(0, 255)):\n",
    "    luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    l_channel = luv[:,:,0]\n",
    "    l_binary_output = np.zeros_like(l_channel)\n",
    "    l_binary_output[(l_channel > l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    return l_binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test LUV\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    l_binary_output = l_color_thresh(img, l_thresh=(210, 255))\n",
    "    # Plot the result\n",
    "    #visualize_results(img, l_binary_output, pname, 'L Color Thresh.%s'%idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B of LAB \n",
    "def b_color_thresh(img, b_thresh=(0, 255)):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    b_channel = lab[:,:,2]\n",
    "    b_binary_output = np.zeros_like(b_channel)\n",
    "    b_binary_output[(b_channel > b_thresh[0]) & (b_channel <= b_thresh[1])] = 1\n",
    "    return b_binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test LAB\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    b_binary_output = b_color_thresh(img, b_thresh=(150, 255))\n",
    "    # Plot the result\n",
    "    #visualize_results(img, b_binary_output, pname, 'B Color Thresh.%s'%idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Color Threshold\n",
    "def comb_color_thresh(img):\n",
    "    r_binary_output = r_color_thresh(img, r_thresh=(215,255))\n",
    "    v_binary_output = v_color_thresh(img, v_thresh=(220,255))\n",
    "    l_binary_output = l_color_thresh(img, l_thresh=(210,255))\n",
    "    b_binary_output = b_color_thresh(img, b_thresh=(150,255))\n",
    "    binary_output = np.zeros_like(l_binary_output)\n",
    "    binary_output[(r_binary_output == 1) | (v_binary_output == 1) | (l_binary_output == 1) | (b_binary_output == 1)] = 1\n",
    "    \n",
    "    #print(\"color transform is done...\")\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test combined color threshold\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    binary_color = comb_color_thresh(birds_eye)\n",
    "    # Plot the result\n",
    "    #visualize_results(img, binary_color, pname, 'Combined Color Thresh.%s'%idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Gradient Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel\n",
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "# Define a function that takes an image, gradient orientation,\n",
    "# and threshold min / max values.\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test abs_sobel_thresh\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    sob_grad_binary = abs_sobel_thresh(test_image, orient='x', thresh_min=20, thresh_max=100)\n",
    "    # Plot the result\n",
    "    #visualize_results(test_image, sob_grad_binary, 'Original Image', 'Sobel Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magnitude \n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the magnitude of the gradient\n",
    "# and applies a threshold\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Calculate the magnitude \n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    # Convert to grayscale\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test mag_thresh\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    mag_binary = mag_thresh(test_image, sobel_kernel=3, mag_thresh=(30, 100))\n",
    "    # Plot the result\n",
    "    #visualize_results(test_image, mag_binary, 'Original Image', 'Magnitude Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction \n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    # Grayscale\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dir_threshold\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    dir_binary = dir_threshold(test_image, sobel_kernel=15, thresh=(0.7, 1.3))\n",
    "    # Plot the result\n",
    "    #visualize_results(test_image, dir_binary, 'Original Image', 'Direction Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined gradient and threshold\n",
    "def comb_grad_thresh(img, ksize=3, sk_size=15, sx_thresh=(0, 255)):\n",
    "    # Choose a Sobel kernel size\n",
    "    ksize = 3 # Choose a larger odd number to smooth gradient measurements\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh_min=sx_thresh[0], thresh_max=sx_thresh[1])\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh_min=sx_thresh[0], thresh_max=sx_thresh[1])\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=sk_size, thresh=(0.7, 1.3))\n",
    "    combined_binary = np.zeros_like(dir_binary)\n",
    "    combined_binary[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test combined gradient threshold\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    comb_binary = comb_grad_thresh(test_image, sx_thresh=(20, 100))\n",
    "    # Plot the result\n",
    "    #visualize_results(test_image, comb_binary, 'Original Image', 'Combined Gradient Thresh.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Color and Gradient Threshold\n",
    "def color_grad_thresh(birds_eye,sx_thresh=(20, 100)):\n",
    "    binary_color = comb_color_thresh(birds_eye)\n",
    "    color_grad_binary = comb_grad_thresh(binary_color, sx_thresh=sx_thresh)\n",
    "    return color_grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test combined gradient threshold\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the function\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    color_grad_binary = color_grad_thresh(birds_eye, sx_thresh=(20, 100))\n",
    "    # Plot the result\n",
    "    #visualize_results(test_image, color_grad_binary, 'Original Image', 'Combined Color and Gradient Thresh.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-5: Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Sliding Windows and Fit a Polynomial\n",
    "def sliding_window_fit_poly(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    rect = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high), (0,255,0), 2) \n",
    "        #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high), (0,255,0), 2) \n",
    "        \n",
    "        rect.append((win_xleft_low,\n",
    "                    win_y_low, \n",
    "                    win_xleft_high,\n",
    "                    win_y_high, \n",
    "                    win_xright_low, \n",
    "                    win_y_low, \n",
    "                    win_xright_high, \n",
    "                    win_y_high))\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Save the data for later use\n",
    "    slide_pickle = {}\n",
    "    slide_pickle[\"left_fit\"] = left_fit\n",
    "    slide_pickle[\"right_fit\"] = right_fit\n",
    "    pickle.dump(slide_pickle, open(\"output_images/wide_slide_pickle.p\", \"wb\" ) )\n",
    "    \n",
    "    #print(\"Sliding window poly fit is done (one time only)\")\n",
    "    return left_fit, right_fit, left_lane_inds, right_lane_inds, leftx , rightx, lefty, righty, rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sliding_fit(binary_warped, left_fit, right_fit, left_lane_inds, right_lane_inds, rect):   \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] # left line\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2] # right line\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0] # left pixels\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255] # right pixels\n",
    "    \n",
    "    for r in rect: \n",
    "        cv2.rectangle(out_img,(r[0],r[1]),(r[2],r[3]),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(r[4],r[5]),(r[6],r[7]),(0,255,0), 2)\n",
    "    \n",
    "    plt.subplots(1, 1, figsize=(10,5))\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow') # left line\n",
    "    plt.plot(right_fitx, ploty, color='yellow') # right line\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize sliding fit\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the functions\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    binary_warped = comb_color_thresh(birds_eye)\n",
    "    # Plot the result\n",
    "    #visualize_results(img, result_binary, pname, 'Color Thresh. Image%s'%idx)\n",
    "    left_fit, right_fit, left_lane_inds, right_lane_inds, _,_,_,_,rect = sliding_window_fit_poly(binary_warped)\n",
    "    # Plot the result\n",
    "    visualize_sliding_fit(binary_warped, left_fit, right_fit, left_lane_inds, right_lane_inds, rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip the sliding windows step once you know where the lines are\n",
    "Now you know where the lines are you have a fit! In the next frame of video you don't need to do a blind search again, but instead you can just search in a margin around the previous line position like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in a margin around the previous line position\n",
    "def prev_line_fit_poly(binary_warped, left_fit, right_fit):\n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_indsx = []\n",
    "    right_lane_indsx = []\n",
    "    \n",
    "    left_lane_indsx = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "    left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_indsx = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "    right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_indsx]\n",
    "    lefty = nonzeroy[left_lane_indsx] \n",
    "    rightx = nonzerox[right_lane_indsx]\n",
    "    righty = nonzeroy[right_lane_indsx]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting \n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    #print(\"Search lane in a margin around previously found line position is done...\")\n",
    "    return left_fitx , right_fitx, left_lane_indsx, right_lane_indsx, leftx, rightx, lefty, righty "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prev_line_fit(binary_warped, left_fitx, right_fitx, left_lane_indsx, right_lane_indsx):\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        \n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_indsx], nonzerox[left_lane_indsx]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_indsx], nonzerox[right_lane_indsx]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    ax , fig = plt.subplots(1, 1, figsize=(10,5))\n",
    "    #print(\"axis dpi =\",ax.dpi)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    #plt.xlim(0, 1280)\n",
    "    #plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize_prev_line_fit\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the functions\n",
    "\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    binary_warped = comb_color_thresh(birds_eye)\n",
    "    left_fitx , right_fitx, left_lane_indsx, right_lane_indsx, leftx, rightx, lefty, righty = prev_line_fit_poly(binary_warped, left_fit, right_fit)\n",
    "    # Plot the result\n",
    "    visualize_prev_line_fit(binary_warped, left_fitx, right_fitx, left_lane_indsx, right_lane_indsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-6: Determine the radius of curvature and car offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring radius of curvature and car offset\n",
    "# https://www.intmath.com/applications-differentiation/8-radius-curvature.php\n",
    "def measure_curve(binary_warped, leftx, rightx, lefty, righty): \n",
    "    yvalue = image.shape[0]\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature - real world (meters)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*yvalue*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*yvalue*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "    \n",
    "    # measure car offset\n",
    "    lane_center = (left_fit_cr[-1] + right_fit_cr[-1])/2 # bottom of the image, position closest to the car\n",
    "    car_camera_center = (binary_warped.shape[1] / 2) * xm_per_pix  # x-axis image midpoint\n",
    "    car_offset = (car_camera_center - lane_center )# if +ve car on right of center of lane\n",
    "    \n",
    "    \n",
    "    #print(\"Measuring curvature and caroffset is done...\")\n",
    "    \n",
    "    return left_curverad, right_curverad, car_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test measure_curve \n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the functions\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    binary_warped = comb_color_thresh(birds_eye)\n",
    "   \n",
    "    left_fitx , right_fitx, left_lane_indsx, right_lane_indsx , leftx , rightx, lefty, righty = prev_line_fit_poly(binary_warped, left_fit, right_fit)\n",
    "    # Plot the result\n",
    "    #visualize_prev_line_fit(result_binary, left_fitx, right_fitx, left_lane_indsx, right_lane_indsx)\n",
    "    left_curverad, right_curverad, car_offset = measure_curve(binary_warped, leftx , rightx, lefty, righty)\n",
    "    print(' %.2f' %left_curverad, ' %.2f' %right_curverad, ' %.2f' %car_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-7: Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warp lane boundaries on original image\n",
    "def warp_lane(image, binary_warped, Minv, left_fitx , right_fitx):\n",
    "    img = np.copy(image)\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.polylines(color_warp, np.int_([pts_left]), isClosed=False, color=(255, 102, 255), thickness=25)\n",
    "    cv2.polylines(color_warp, np.int_([pts_right]), isClosed=False, color=(255, 102, 255), thickness=25)\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (binary_warped.shape[1], binary_warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    newresult = cv2.addWeighted(img, 1, newwarp, 0.6, 0)\n",
    "    #print(\"Wrap lane boundaries on original image is done...\")\n",
    "    return newresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test warp_lane\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the functions\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    \n",
    "    result_binary  = comb_color_thresh(birds_eye)\n",
    "\n",
    "    left_fitx , right_fitx, left_lane_indsx, right_lane_indsx, leftx , rightx, lefty, righty = prev_line_fit_poly(result_binary, left_fit, right_fit)\n",
    "    newresult = warp_lane(img, result_binary, Minv, left_fitx , right_fitx)\n",
    "    # Plot the result\n",
    "    #visualize_results(img, newresult, 'Test Image', 'Result Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-8: Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_position(image, left_curverad , right_curverad, car_offset):\n",
    "    img = np.copy(image)\n",
    "\n",
    "    if (car_offset >= 0):\n",
    "        direction = 'right'\n",
    "        text_d = 'Radius of Curvature = %.2f' %right_curverad + ' (m)'\n",
    "    else:\n",
    "        direction = 'left'\n",
    "        text_d = 'Radius of Curvature = %.2f' %left_curverad + ' (m)'\n",
    "    car_offset_abs = abs(car_offset)\n",
    "    text_p = 'Vehicle is %.2f' %car_offset_abs + ' m' + ' %s' %direction + ' of center'\n",
    "    \n",
    "    org1 = (50, 50)\n",
    "    org2 = (50, 100)\n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 1\n",
    "    color = (204, 255, 255)\n",
    "    thickness = 2\n",
    "    \n",
    "    cv2.putText(img, text_d, org1, fontFace, fontScale, color, thickness)   \n",
    "    cv2.putText(img, text_p, org2, fontFace, fontScale, color, thickness)\n",
    "    #print(\"Output visual display is done...\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test display_position\n",
    "%matplotlib inline\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the functions\n",
    "    birds_eye, M, Minv = corners_unwarp(img)\n",
    "    result_binary  = comb_color_thresh(birds_eye)\n",
    "   \n",
    "    left_fitx , right_fitx, left_lane_indsx, right_lane_indsx, leftx , rightx, lefty, righty = prev_line_fit_poly(result_binary, left_fit, right_fit)\n",
    "    left_curverad, right_curverad, car_offset = measure_curve(result_binary, leftx , rightx, lefty, righty)\n",
    "    result_warp = warp_lane(img, result_binary, Minv, left_fitx , right_fitx)\n",
    "    result_position = display_position(result_warp, left_curverad , right_curverad, car_offset )\n",
    "    # Plot the result\n",
    "    visualize_results(img, result_position, 'Test Image', 'Result Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect lane pixels and fit to find the lane boundary \n",
    "    #slide_pickle = pickle.load(open(\"output_images/wide_slide_pickle.p\" , \"rb\" ) )\n",
    "    #left_fitc = slide_pickle[\"left_fit\"]\n",
    "    #right_fitc = slide_pickle[\"right_fit\"]\n",
    "    #left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc = prev_line_fit_poly(result_binaryc, left_fitc, right_fitc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-9: Line fit based on sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        self.n = 5\n",
    "\n",
    "    def write_fit(self, *args):\n",
    "        # save last n values\n",
    "        if len(self.recent_xfitted) <= self.n:\n",
    "            self.recent_xfitted.append(args)\n",
    "        else:\n",
    "            del self.recent_xfitted[-1]\n",
    "            self.recent_xfitted.append(args)\n",
    "        \n",
    "        \n",
    "    def read_fit(self):\n",
    "        # read last value\n",
    "        #print(\"length=\",len(self.recent_xfitted))\n",
    "        fitx, lane_indsx, x, y = self.recent_xfitted[-1]\n",
    "        return fitx, lane_indsx, x, y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line fit based on sanity check - was a line detected in the last iteration?\n",
    "def line_fit(left_line, right_line, result_binaryc):\n",
    "    #print(\"line_fit\")\n",
    "    # initial\n",
    "    left_fits, right_fits, left_lane_indss, right_lane_indss, leftxs , rightxs, leftys, rightys, _ = sliding_window_fit_poly(result_binary)\n",
    "    # next\n",
    "    left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc = prev_line_fit_poly(result_binaryc, left_fits, right_fits)      \n",
    "    return left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check new fit results\n",
    "#def sanity_check(leftxc , rightxc):\n",
    "def sanity_check(leftxc , rightxc):\n",
    "    sanity = False\n",
    "    #diff is 700 +/- margin \n",
    "    diff = np.max(rightxc) - np.min(leftxc)\n",
    "    if diff <= 950:\n",
    "        sanity = True\n",
    "    return sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sanity_check\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc = line_fit(left_line, right_line, result_binary)  \n",
    "print(np.max(rightxc))\n",
    "print(np.min(leftxc))\n",
    "diff = np.max(rightxc) - np.min(leftxc)\n",
    "print(diff)\n",
    "sanity = sanity_check(leftxc , rightxc)\n",
    "print(sanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write new good fit result\n",
    "def write_good_fit(left_line, right_line, left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc): \n",
    "    #print(\"write_good_fit\")\n",
    "    left_line.write_fit(left_fitxc, left_lane_indsxc, leftxc, leftyc)\n",
    "    right_line.write_fit(right_fitxc, right_lane_indsxc, rightxc, rightyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read last good fit result\n",
    "def read_good_fit(left_line, right_line):\n",
    "    #print(\"read_good_fit\")\n",
    "    left_fitxc, left_lane_indsxc, leftxc, leftyc = left_line.read_fit()\n",
    "    right_fitxc, right_lane_indsxc, rightxc, rightyc = right_line.read_fit()\n",
    "    return left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lane boundary fit with curve measurement\n",
    "def lane_bound_fit(left_line, right_line, result_binaryc):\n",
    "    #print(\"lane_bound_fit\")\n",
    "    left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc = line_fit(left_line, right_line, result_binaryc)    \n",
    "    sanity = sanity_check(leftxc , rightxc)\n",
    "    if sanity == True:\n",
    "        write_good_fit(left_line, right_line, left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc)\n",
    "        write_good_fit(left_line, right_line, left_fitxc , right_fitxc, left_lane_indsxc, right_lane_indsxc, leftxc , rightxc, leftyc, rightyc)\n",
    "    #else:\n",
    "        #print(\"Sanity Check - reading previous data\")\n",
    "    left_fitxcr , right_fitxcr, left_lane_indsxcr, right_lane_indsxcr, leftxcr , rightxcr, leftycr, rightycr = read_good_fit(left_line, right_line)\n",
    "    left_curverad, right_curverad, car_offset = measure_curve(result_binaryc, leftxcr , rightxcr, leftycr, rightycr)\n",
    "    return left_curverad, right_curverad, car_offset, left_fitxcr , right_fitxcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lane_bound_fit\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "left_curverad, right_curverad, car_offset, left_fitxcr , right_fitxcr = lane_bound_fit(left_line, right_line, result_binary)\n",
    "#print(left_fitxcr , right_fitxcr, left_lane_indsxcr, right_lane_indsxcr, leftxcr , rightxcr, leftycr, rightycr)\n",
    "print(left_curverad, right_curverad, car_offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-10: Integrate the pipeline and test on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating the advanced lane finding pipeline\n",
    "def advanced_lane_finding(image):\n",
    "    imgf = np.copy(image)   \n",
    "    \n",
    "    # perspective transform\n",
    "    birds_eyef, Mf, Minvf = corners_unwarp(imgf)\n",
    "    \n",
    "    # color and/or gradient threshold\n",
    "    result_binaryf = color_grad_thresh(birds_eyef, sx_thresh=(20, 100))\n",
    "        \n",
    "    # lane boundary fit \n",
    "    left_curveradf, right_curveradf, car_offsetf, left_fitxf , right_fitxf = lane_bound_fit(left_line, right_line, result_binaryf)    \n",
    "    \n",
    "    # warp lane boundaries on original image\n",
    "    result_warpf = warp_lane(imgf, result_binaryf, Minvf, left_fitxf , right_fitxf)\n",
    "    \n",
    "    # output visual display \n",
    "    result_image = display_position(result_warpf, left_curveradf , right_curveradf, car_offsetf )\n",
    "    \n",
    "    #print(\"Advanced lane finding done!\")\n",
    "\n",
    "    return result_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "# Test on all test images\n",
    "t_images = sorted(glob.glob('output_images/output_test*'))\n",
    "for idx, pname in enumerate(t_images):\n",
    "    # Read images\n",
    "    img = cv2.imread(pname)\n",
    "    # Run the functions  \n",
    "    #print(idx)\n",
    "    result_image = advanced_lane_finding(img)\n",
    "    # Plot the result\n",
    "    visualize_results(img, result_image, 'Test Image', 'Result Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-11: Test on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if not os.path.exists('test_videos_output'):\n",
    "    os.mkdir('test_videos_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test with project_video.mp4\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "white_output = 'test_videos_output/project_video.mp4'\n",
    "#clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(0,10)\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "white_clip = clip1.fl_image(advanced_lane_finding) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with project_video.mp4\n",
    "white_output = 'test_videos_output/challenge_video.mp4'\n",
    "clip2 = VideoFileClip(\"test_videos/challenge_video.mp4\")\n",
    "white_clip = clip2.fl_image(advanced_lane_finding) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with project_video.mp4\n",
    "white_output = 'test_videos_output/harder_challenge_video.mp4'\n",
    "clip3 = VideoFileClip(\"test_videos/harder_challenge_video.mp4\")\n",
    "white_clip = clip3.fl_image(advanced_lane_finding) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
